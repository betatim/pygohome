{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pygohome\n",
    "\n",
    "## Python, Let's Go Home. Quickly.\n",
    "\n",
    "*pygohome* is a 100% personal route optimizer in a known environment based on experience.\n",
    "\n",
    "*You* walk/ride/drive frequently between known locations (home, work, school, shops, family, friends, …) using different routes, but would like to know the optimal route, that should take you the less time possible? *pygohome* uses your recorded GPX tracks to build a route network of *your* world with estimation on how long *you* need to get from A to B using the mean of transport of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How it works\n",
    "\n",
    "1. **Choose your mean of transport.** Bicycle works great, walking should too. Motorized vehicles may be served better by real-time online services.\n",
    "\n",
    "2. **Track all your trips** using that mean of transport. Start the tracking before you leave, stop the tracking after you arrive. Ride/walk/drive normally, stop at lights, don't speed. OsmAnd works great (list of other apps needed). 1 or 2 seconds tracking interval is ok.\n",
    "\n",
    "3. **Add POIs (and intersections) as waypoints.** Transfer all GPX files to your computer into a directory (OsmAnd names them `YYYY-MM-DD_HH-MM_DDD.gpx`). Load all of them into some GPX editor (JOSM works great). Create a new GPX file and add all points of interest (home, work, or any place where you started, deliberately paused or ended a trip) with an attribute `name=…`. Then add unnamed waypoints on each intersection where your tracks cross, split, or join. Save this as `pois.gpx`.\n",
    "\n",
    "4. **Convert all GPX files (tracks and pois.gpx) into CSV using gpsbabel.** If all GPX files are in the `gpx` directory and all CSV files in `csv`, then:\n",
    "\n",
    "```bash\n",
    "for x in gpx/20*gpx; gpsbabel -t -i gpx -f $x -o unicsv,grid=utm -F csv/${x:t:r}.csv\n",
    "    \n",
    "gpsbabel -w -i gpx -f gpx/pois.gpx -o unicsv,grid=utm -F csv/pois.csv\n",
    "```\n",
    "\n",
    "5. **Run the cell below**\n",
    "\n",
    "6. **Call the method `fastest_path(src, dst, quantile=0.8)`** where `src` and `dst` are the names of the POIs as string and `quantile` is the a float number between `0.0` (take into account your best time on each road segment) and `1.0` (worst time), while `0.8` is a safe value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import math\n",
    "import statistics\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import ipyleaflet as lf\n",
    "import pandas as pd\n",
    "from scipy.spatial import cKDTree\n",
    "import utm\n",
    "\n",
    "# load nodes (POIs and intersections)\n",
    "nodes = pd.read_csv(\n",
    "    \"csv/pois.csv\", usecols=[\"Name\", \"UTM-Zone\", \"UTM-Ch\", \"UTM-East\", \"UTM-North\"]\n",
    ")\n",
    "pois = {name: i for i, name in nodes[\"Name\"].items() if not name.startswith(\"WPT\")}\n",
    "\n",
    "# load all tracks into a single DataFrame\n",
    "dfr = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(\n",
    "            path,\n",
    "            usecols=[\"Date\", \"Time\", \"UTM-Zone\", \"UTM-Ch\", \"UTM-East\", \"UTM-North\"],\n",
    "            parse_dates=[[\"Date\", \"Time\"]],\n",
    "        )\n",
    "        for path in sorted(Path(\"csv\").glob(\"20*.csv\"))\n",
    "    ]\n",
    ").sort_values(\"Date_Time\")\n",
    "\n",
    "# make sure all tracks and POIs are in the same UTM zone:\n",
    "utm_zones = set(nodes[\"UTM-Zone\"]) | set(dfr[\"UTM-Zone\"])\n",
    "utm_chs = set(nodes[\"UTM-Ch\"]) | set(dfr[\"UTM-Ch\"])\n",
    "if len(utm_zones) == len(utm_chs) == 1:\n",
    "    utm_zone = utm_zones.pop()\n",
    "    utm_ch = utm_chs.pop()\n",
    "else:\n",
    "    raise Exception(f\"Not a unique UTM Zone ({utm_zones!r}, {utm_chs!r})\")\n",
    "\n",
    "# split into segments (at least 1 minute break between points)\n",
    "dfr[\"segment\"] = (dfr[\"Date_Time\"].diff() > pd.Timedelta(\"00:01:00\")).cumsum()\n",
    "\n",
    "# calculate offset to the first record of each segment in seconds\n",
    "dfr[\"offset\"] = (\n",
    "    dfr[\"Date_Time\"] - dfr.groupby(\"segment\")[\"Date_Time\"].transform(\"first\")\n",
    ").dt.total_seconds()\n",
    "\n",
    "# build a KDTree of all nodes and find if trackpoints are closer than 30 meters from them\n",
    "tree = cKDTree(nodes[[\"UTM-East\", \"UTM-North\"]])\n",
    "dfr[\"node\"] = tree.query(dfr[[\"UTM-East\", \"UTM-North\"]], distance_upper_bound=30)[1]\n",
    "dfr = dfr[dfr.node < tree.n]\n",
    "\n",
    "# for each passage by a node get the offset of the first and the last point\n",
    "dfr = dfr.groupby((dfr.node != dfr.groupby(\"segment\")[\"node\"].shift(1)).cumsum()).agg(\n",
    "    segment=(\"segment\", \"first\"),\n",
    "    start=(\"offset\", \"first\"),\n",
    "    end=(\"offset\", \"last\"),\n",
    "    node=(\"node\", \"first\"),\n",
    ")\n",
    "\n",
    "# `pred_secs` between leaving 30m radius of `pred_node` and entering 30m radius of `curr_node`\n",
    "# `curr_secs` between entering and leaving the 30m radius of `curr_node`\n",
    "# `succ_secs` between leaving 30m radius of `curr_node` and entering 30m radius of `succ_node`\n",
    "pred_dfr = dfr.groupby(\"segment\").shift(1, fill_value=-1)\n",
    "succ_dfr = dfr.groupby(\"segment\").shift(-1, fill_value=-1)\n",
    "df2 = pd.DataFrame(\n",
    "    {\n",
    "        \"pred_node\": pred_dfr[\"node\"],\n",
    "        \"curr_node\": dfr[\"node\"],\n",
    "        \"succ_node\": succ_dfr[\"node\"],\n",
    "        \"pred_secs\": dfr[\"start\"] - pred_dfr[\"end\"],\n",
    "        \"curr_secs\": dfr[\"end\"] - dfr[\"start\"],\n",
    "        \"succ_secs\": succ_dfr[\"start\"] - dfr[\"end\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "# gpsbabel names unnamed waypoints as WPTxxxxx\n",
    "is_poi = ~df2.join(nodes, on=\"curr_node\")[\"Name\"].str.startswith(\"WPT\")\n",
    "\n",
    "# an intersection is \"slow\" (traffic lights)\n",
    "# if at least 25% of tracks spend more than 20 seconds within 30 meters of its node\n",
    "is_slow = df2.groupby(\"curr_node\")[\"curr_secs\"].transform(\n",
    "    lambda x: x.quantile(0.75) > 20\n",
    ")\n",
    "\n",
    "# build the graph\n",
    "g = nx.DiGraph()\n",
    "grp_slow = (\n",
    "    df2[~is_poi & is_slow]\n",
    "    .query(\"pred_node >=0 and succ_node >= 0\")\n",
    "    .groupby([\"pred_node\", \"curr_node\", \"succ_node\"])\n",
    ")\n",
    "g.add_edges_from(\n",
    "    (\n",
    "        ((c, p, c), (c, c, s), {\"secs\": sorted(grp[\"curr_secs\"])})\n",
    "        for (p, c, s), grp in grp_slow\n",
    "    )\n",
    ")\n",
    "\n",
    "df2[\"succ_secs\"] += df2[~is_poi & ~is_slow][\"curr_secs\"].reindex(df2.index).fillna(0)\n",
    "df2.loc[~is_poi & ~is_slow, \"curr_secs\"] = 0\n",
    "\n",
    "grp_simple = df2.query(\"succ_node >= 0\").groupby([\"curr_node\", \"succ_node\"])\n",
    "g.add_edges_from(\n",
    "    (\n",
    "        (\n",
    "            (c, c, s) if (c, c, s) in g else c,\n",
    "            (s, c, s) if (s, c, s) in g else s,\n",
    "            {\"secs\": sorted(grp[\"succ_secs\"])},\n",
    "        )\n",
    "        for (c, s), grp in grp_simple\n",
    "    )\n",
    ")\n",
    "\n",
    "pos = {i: np.array([rec[\"UTM-East\"], rec[\"UTM-North\"]]) for i, rec in nodes.iterrows()}\n",
    "for node in g.nodes:\n",
    "    if isinstance(node, tuple):\n",
    "        # nodes in slow intersections are positioned on a circle\n",
    "        # of radius 30m in the direction of the predecessor/successor\n",
    "        # and always on the right side\n",
    "        # (has no impact on results, only on the map)\n",
    "        here, src, dst = node\n",
    "        step = (30 * (pos[dst] - pos[src]) / math.hypot(*(pos[dst] - pos[src]))).astype(\n",
    "            int\n",
    "        )\n",
    "        if here == src:\n",
    "            pos[node] = pos[here] + step + np.array([step[1], -step[0]]) // 6\n",
    "        else:\n",
    "            pos[node] = pos[here] - step - np.array([step[1], -step[0]]) // 6\n",
    "\n",
    "\n",
    "def fastest_path(src, dst, quantile=0.8):\n",
    "    src_poi = pois[src]\n",
    "    dst_poi = pois[dst]\n",
    "\n",
    "    src_latlon = utm.to_latlon(pos[src_poi][0], pos[src_poi][1], utm_zone, utm_ch)\n",
    "    m = lf.Map(\n",
    "        center=src_latlon,\n",
    "        zoom=14,\n",
    "        interpolation=\"nearest\",\n",
    "        basemap=lf.basemaps.CartoDB.DarkMatter,\n",
    "    )\n",
    "\n",
    "    sp = nx.path_graph(\n",
    "        nx.dijkstra_path(\n",
    "            g, src_poi, dst_poi, lambda u, v, a: np.quantile(a[\"secs\"], quantile)\n",
    "        )\n",
    "    )\n",
    "    line = lf.AntPath(\n",
    "        locations=[\n",
    "            utm.to_latlon(pos[node][0], pos[node][1], utm_zone, utm_ch) for node in sp\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    m.add_layer(line)\n",
    "    nd = sum(\n",
    "        statistics.NormalDist.from_samples(g.edges[edge][\"secs\"])\n",
    "        if len(g.edges[edge][\"secs\"]) > 1\n",
    "        else statistics.NormalDist(g.edges[edge][\"secs\"][0], 0)\n",
    "        for edge in sp.edges\n",
    "    )\n",
    "    qu = sum(np.quantile(g.edges[edge][\"secs\"], quantile) for edge in sp.edges)\n",
    "\n",
    "    print(\n",
    "        \"quantile {:.2f}: {:2d}:{:02d} (norm: {:2d}:{:02d}±{:d}:{:02d})   \"\n",
    "        \"{} (nb of measurements/segment)\".format(\n",
    "            quantile,\n",
    "            *divmod(int(qu), 60),\n",
    "            *divmod(int(nd.mean), 60),\n",
    "            *divmod(int(nd.stdev), 60),\n",
    "            \"·\".join(str(len(g.edges[edge][\"secs\"])) for edge in sp.edges),\n",
    "        )\n",
    "    )\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastest_path(\"hbf\", \"schloss\", 0.8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
